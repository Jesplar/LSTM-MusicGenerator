{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script for creating and training the LSTM network models used to generate classical music.\n",
    "\n",
    "Matilda Wikström\n",
    "\n",
    "Jesper Larsson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to good stuff!\n",
    "\n",
    "https://github.com/craffel/pretty-midi\n",
    "\n",
    "https://towardsdatascience.com/generate-piano-instrumental-music-by-using-deep-learning-80ac35cdbd2e\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "from random import shuffle, seed\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "# \"Our code\"\n",
    "import preprocessing as pp\n",
    "#import generatemidi as gm # Broken file, fix\n",
    "import tokenizer as token\n",
    "import generatemidi as gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29070\n"
     ]
    }
   ],
   "source": [
    "# Using pretty_midi example\n",
    "fs=30\n",
    "dict_note = {}\n",
    "midi_pretty_format = pretty_midi.PrettyMIDI('test.midi')\n",
    "piano_midi = midi_pretty_format.instruments[0] # Get the piano channels\n",
    "piano_roll = piano_midi.get_piano_roll(fs=fs)\n",
    "dict_note[0] = piano_roll\n",
    "\n",
    "print(len(piano_roll[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the required data create folder structure\n",
    "#Make sure we are in the correct folder\n",
    "\n",
    "assert (os.path.basename(os.getcwd())=='LSTM-MusicGenerator'), \"Wrong working dir\"\n",
    "\n",
    "#Download the MAESTRO Dataset\n",
    "if not os.path.isfile('./maestro-v1.0.0-midi.zip'):\n",
    "    !wget https://storage.googleapis.com/magentadata/datasets/maestro/v1.0.0/maestro-v1.0.0-midi.zip\n",
    "\n",
    "#Check if we have extracted the files\n",
    "if not os.path.isdir('./maestro-v1.0.0-midi') and not os.path.isfile('./maestro-v1.0.0/LICENSE'):\n",
    "    !unzip maestro-v1.0.0-midi.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0352cc329a154c359f0d893e4e15d5e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "list_all_midi = pp.get_list_midi() # \n",
    "sampled_200_midi = list_all_midi[0:100]\n",
    "batch = 1\n",
    "start_index = 0\n",
    "note_tokenizer = token.NoteTokenizer()\n",
    "import pretty_midi\n",
    "\n",
    "for i in tqdm_notebook(range(len(sampled_200_midi))):\n",
    "    dict_time_notes = token.generate_dict_time_notes(sampled_200_midi, batch_song=1, start_index=i, use_tqdm=False, fs=5)\n",
    "    full_notes = token.process_notes_in_song(dict_time_notes)\n",
    "    for note in full_notes:\n",
    "        note_tokenizer.partial_fit(list(note.values()))\n",
    "note_tokenizer.add_new_note('e') # Add empty notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "\n",
    "#unique_notes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Input dimension = 50\n",
    "#Batch dimension = ? May be one, since we are putting them on \n",
    "#Hidden size, try different versions\n",
    "   \n",
    "input_size = 50\n",
    "hidden_size = 20\n",
    "num_layers = 4\n",
    "is_bidirectional = True\n",
    "#dropout_rate = 0.75\n",
    "dropout_rate = 0\n",
    "batch_size = 1 #96 ### Should be 2085\n",
    "\n",
    "seq_len = 50\n",
    "EPOCHS = 4\n",
    "BATCH_SONG = 16\n",
    "BATCH_NNET_SIZE = 96 \n",
    "TOTAL_SONGS = len(sampled_200_midi)\n",
    "FRAME_PER_SECOND = 5\n",
    "\n",
    "\n",
    "unique_notes = note_tokenizer.unique_word #Used in our output layer to map\n",
    "\n",
    "\n",
    "\n",
    "if is_bidirectional:\n",
    "    num_directions = 2\n",
    "else:\n",
    "    num_directions = 1\n",
    "\n",
    "#input = torch.randn(1, batch_size, input_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class our_LSTM(torch.nn.Module):\n",
    "    def __init__(self, h0, c0):\n",
    "        super().__init__()\n",
    "        self.hn = h0\n",
    "        self.cn = c0\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout_rate, bidirectional=is_bidirectional)\n",
    "        self.fc = torch.nn.Linear(num_directions * hidden_size, unique_notes)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        out, (self.hn, self.cn) = self.lstm(inp, (self.hn, self.cn))\n",
    "        out = self.fc(out)\n",
    "        #out = self.softmax(out)\n",
    "        out = out.permute(0,2,1)\n",
    "        out = out.view(-1,unique_notes)\n",
    "        \n",
    "        return out, self.hn, self.cn\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987fbcbc25864612a42a4004a5c9973a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='i', max=7, style=ProgressStyle(description_width='initial')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a741f4dea91847afbbb20d1894d9e2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='j', max=437, style=ProgressStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Training loop\n",
    "seq_len = 50 # input length here.\n",
    "EPOCHS = 4\n",
    "BATCH_SONG = 16\n",
    "BATCH_NNET_SIZE = 96 # Our sequence length here.\n",
    "TOTAL_SONGS = len(sampled_200_midi)\n",
    "FRAME_PER_SECOND = 5\n",
    "from torch import optim\n",
    "hn = torch.randn(num_layers*num_directions, batch_size, hidden_size,dtype=torch.float32)\n",
    "cn = torch.randn(num_layers*num_directions, batch_size, hidden_size,dtype=torch.float32)\n",
    "model = our_LSTM(hn,cn)\n",
    "\n",
    "#out, h, c = model(in_tensor, h0, c0) # Expects input with a batch dimension.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "##Train\n",
    "\n",
    "for epoch in range(0,5):\n",
    "    batch_song = BATCH_SONG\n",
    "    frame_per_second = FRAME_PER_SECOND\n",
    "    shuffle(sampled_200_midi)\n",
    "    for i in tqdm_notebook(range(0,len(sampled_200_midi),BATCH_SONG), desc='i'):\n",
    "        #print(\"i=:\",i)\n",
    "        inputs_nnet_large, outputs_nnet_large = token.generate_batch_song(\n",
    "                sampled_200_midi, batch_song, start_index=i, fs=frame_per_second, \n",
    "                seq_len=seq_len, use_tqdm=False)\n",
    "\n",
    "        trans_in = note_tokenizer.transform(inputs_nnet_large)\n",
    "        trans_out = note_tokenizer.transform(outputs_nnet_large)\n",
    "        #print(\"Max of out: \", max(trans_out), \"Min of out :\", min(trans_out))\n",
    "        trans_out = trans_out - 1\n",
    "        counter = 0\n",
    "        model.hn.detach_() \n",
    "        model.cn.detach_()\n",
    "        for j in tqdm_notebook(range(0,len(trans_in)-BATCH_NNET_SIZE,BATCH_NNET_SIZE), desc='j'):\n",
    "            counter += 1 \n",
    "            #print(\"j=:\",j)\n",
    "            #Want to iterate over the sequence in steps of 96\n",
    "            input_tensor = trans_in[j:j+BATCH_NNET_SIZE]\n",
    "            target_tensor = trans_out[j:j+BATCH_NNET_SIZE]\n",
    "            #print(\"Max of target tensor: \", max(target_tensor), \"Min of target tensor: \", min(target_tensor))\n",
    "\n",
    "            input_tensor = torch.tensor(input_tensor,dtype=torch.float32)\n",
    "            input_tensor = input_tensor[None,:,:] # Should be (seq_len, batch, input_size)\n",
    "            input_tensor = input_tensor.permute(1,0,2)\n",
    "            #print(input_tensor.shape)\n",
    "            target_tensor = torch.tensor(target_tensor,dtype=torch.long).view(-1)\n",
    "            pred, hn, cn = model(input_tensor)\n",
    "            #print(\"Pred shape: \", pred.shape)\n",
    "            #print(\"Target shape: \", target_tensor.shape)\n",
    "            loss = loss_fn(pred,target_tensor)\n",
    "            loss.backward(retain_graph=True)\n",
    "            #if (counter % 50==0): # Resets the hidden states every 50 iteration to speed up the learning\n",
    "            #    ;# Should probably be replaced by batch dimension.\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            #print(loss/96)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_from_random(unique_notes, seq_len=50):\n",
    "  generate = np.random.randint(0,unique_notes-1,seq_len).tolist()\n",
    "  return generate\n",
    "    \n",
    "def generate_from_one_note(note_tokenizer, new_notes='35'):\n",
    "  generate = [note_tokenizer.notes_to_index['e'] for i in range(49)]\n",
    "  generate += [note_tokenizer.notes_to_index[new_notes]]\n",
    "  return generate\n",
    "\n",
    "def generate_notes(generate, model, unique_notes, max_generated=1000, seq_len=50):\n",
    "  for i in tqdm_notebook(range(max_generated), desc='genrt'):\n",
    "    test_input = np.array([generate])[:,i:i+seq_len]\n",
    "    test_input = torch.tensor(test_input, dtype=torch.float32)\n",
    "    test_inputa = test_input[None,:,:]\n",
    "    #print(test_inputa.shape)\n",
    "    print(test_inputa)\n",
    "    predicted_note, _, _ = model(test_inputa)\n",
    "    #random_note_pred = np.random.choice(unique_notes+1, 1, replace=False, p=predicted_note[0])\n",
    "    #generate.append(random_note_pred[0])\n",
    "    #print(predicted_note.shape)\n",
    "    generate.append(predicted_note.argmax(dim=1).item())\n",
    "  return generate\n",
    "\n",
    "\n",
    "def write_midi_file_from_generated(generate, midi_file_name = \"result.mid\", start_index=0, fs=8, max_generated=1000):\n",
    " note_string = [note_tokenizer.index_to_notes[ind_note] for ind_note in generate]\n",
    " array_piano_roll = np.zeros((128,max_generated+1), dtype=np.int16)\n",
    " for index, note in enumerate(note_string[start_index:]):\n",
    "   if note == 'e':\n",
    "     pass\n",
    "   else:\n",
    "     splitted_note = note.split(',')\n",
    "     for j in splitted_note:\n",
    "       array_piano_roll[int(j),index] = 1\n",
    " generate_to_midi = pp.piano_roll_to_pretty_midi(array_piano_roll, fs=fs)\n",
    " print(\"Tempo {}\".format(generate_to_midi.estimate_tempo()))\n",
    " for note in generate_to_midi.instruments[0].notes:\n",
    "   note.velocity = 100\n",
    " generate_to_midi.write(midi_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_generate = 200\n",
    "unique_notes = note_tokenizer.unique_word\n",
    "print(unique_notes)\n",
    "seq_len=50\n",
    "generate = generate_from_random(unique_notes-1, seq_len)\n",
    "print(generate)\n",
    "generate = generate_notes(generate, model, unique_notes, max_generate, seq_len)\n",
    "print(generate)\n",
    "write_midi_file_from_generated(generate, \"hello.mid\", start_index=seq_len-1, fs=7, max_generated = max_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_generate = 300\n",
    "unique_notes = note_tokenizer.unique_word\n",
    "seq_len=50\n",
    "generate = generate_from_one_note(note_tokenizer, '72')\n",
    "generate = generate_notes(generate, model, unique_notes, max_generate, seq_len)\n",
    "print(generate)\n",
    "write_midi_file_from_generated(generate, \"one_note.mid\", start_index=seq_len-1, fs=8, max_generated = max_generate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
